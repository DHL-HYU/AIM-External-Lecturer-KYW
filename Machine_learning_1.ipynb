{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "defPath = 'C:\\\\workshop_221130\\\\' # change to the path where the data is located\n",
    "fileName = 'MMN_workshop_data.mat'\n",
    "\n",
    "filePath = os.path.join(defPath, fileName)\n",
    "\n",
    "loadedMat = scipy.io.loadmat(filePath)\n",
    "\n",
    "MMN = loadedMat['MMN']\n",
    "\n",
    "#%% Feature selection\n",
    "x = MMN[0:30, 0:9]\n",
    "y = MMN[30:60, 0:9]\n",
    "\n",
    "h, p = scipy.stats.ttest_ind(x, y)\n",
    "B = np.sort(p)\n",
    "I = np.argsort(p)\n",
    "\n",
    "#%% 분류를 위한 data 준비\n",
    "data = MMN[:,[5,8]]\n",
    "group = MMN[:,-1]\n",
    "\n",
    "#%% Cross-validation\n",
    "number_kfold = 10\n",
    "indices = StratifiedKFold(number_kfold)\n",
    "\n",
    "#%% LDA (linear discriminant analysis)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "accuracy_LDA = np.zeros(number_kfold)\n",
    "sensitivity_LDA = np.zeros(number_kfold)\n",
    "specificity_LDA = np.zeros(number_kfold)\n",
    "cnt = 0\n",
    "\n",
    "for trainInd, testInd in indices.split(data, group):\n",
    "    train = data[trainInd]\n",
    "    test = data[testInd]\n",
    "    trainGroup = group[trainInd]\n",
    "    testGroup = group[testInd]\n",
    "    \n",
    "    LDAmodel = LinearDiscriminantAnalysis()\n",
    "    LDAmodel.fit(train, trainGroup)\n",
    "    \n",
    "    predictedLabel = LDAmodel.predict(test)\n",
    "    confusionMatrix = confusion_matrix(testGroup, predictedLabel)\n",
    "    \n",
    "    TP = confusionMatrix[0,0]\n",
    "    TN = confusionMatrix[1,1]\n",
    "    FP = confusionMatrix[1,0]\n",
    "    FN = confusionMatrix[0,1]\n",
    "    \n",
    "    accuracy_LDA[cnt] = (TP+TN)/(TP+FP+FN+TN)\n",
    "    sensitivity_LDA[cnt] = TP/(TP+FN)\n",
    "    specificity_LDA[cnt] = TN/(TN+FP)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "final_accuracy_LDA = np.mean(accuracy_LDA)*100\n",
    "final_sensitivity_LDA = np.mean(sensitivity_LDA)*100\n",
    "final_specificity_LDA = np.mean(specificity_LDA)*100\n",
    "\n",
    "#%% LDA plot\n",
    "X0, X1 = data[group==1], data[group==2]\n",
    "\n",
    "plt.scatter(X0[:,0], X0[:, 1], color=\"red\")\n",
    "plt.scatter(X1[:,0], X1[:, 1], color=\"blue\")\n",
    "\n",
    "xlimit = [-8.2, 1.3]\n",
    "ylimit = [-8.2, 1.3]\n",
    "\n",
    "x_min, x_max = xlimit[0], xlimit[1]\n",
    "y_min, y_max = ylimit[0], ylimit[1]\n",
    "\n",
    "plt.xlim(xlimit); plt.ylim(ylimit)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 2000), np.linspace(y_min, y_max, 2000))\n",
    "Z = LDAmodel.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z[:, 1].reshape(xx.shape) >= 0.5\n",
    "\n",
    "cmap = matplotlib.colormaps['Pastel1']\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap , zorder=0)\n",
    "plt.contour(xx, yy, Z, [0.5], linewidths=2.0)\n",
    "\n",
    "\n",
    "#%% SVM (Support vector machine)\n",
    "from sklearn import svm\n",
    "\n",
    "accuracy_SVM = np.zeros(number_kfold)\n",
    "sensitivity_SVM = np.zeros(number_kfold)\n",
    "specificity_SVM = np.zeros(number_kfold)\n",
    "cnt = 0\n",
    "\n",
    "for trainInd, testInd in indices.split(data, group):\n",
    "    train = data[trainInd]\n",
    "    test = data[testInd]\n",
    "    trainGroup = group[trainInd]\n",
    "    testGroup = group[testInd]\n",
    "    \n",
    "    # SVMmodel = svm.LinearSVC(C=1, max_iter=10000)\n",
    "    # SVMmodel = svm.SVC(C=1, kernel=\"poly\", degree=2)\n",
    "    # SVMmodel = svm.SVC(C=1, kernel=\"poly\", degree=3)\n",
    "    SVMmodel = svm.SVC(C=1, kernel=\"rbf\")\n",
    "    SVMmodel.fit(train, trainGroup)\n",
    "    \n",
    "    predictedLabel = SVMmodel.predict(test)\n",
    "    confusionMatrix = confusion_matrix(testGroup, predictedLabel)\n",
    "    \n",
    "    TP = confusionMatrix[0,0]\n",
    "    TN = confusionMatrix[1,1]\n",
    "    FP = confusionMatrix[1,0]\n",
    "    FN = confusionMatrix[0,1]\n",
    "    \n",
    "    accuracy_SVM[cnt] = (TP+TN)/(TP+FP+FN+TN)\n",
    "    sensitivity_SVM[cnt] = TP/(TP+FN)\n",
    "    specificity_SVM[cnt] = TN/(TN+FP)\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "final_accuracy_SVM = np.mean(accuracy_SVM)*100\n",
    "final_sensitivity_SVM = np.mean(sensitivity_SVM)*100\n",
    "final_specificity_SVM = np.mean(specificity_SVM)*100\n",
    "\n",
    "#%% SVM plot\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "X0, X1 = data[group==1], data[group==2]\n",
    "\n",
    "DecisionBoundaryDisplay.from_estimator(SVMmodel, data, ax=plt.gca(),\n",
    "        grid_resolution=2000, response_method=\"predict\", cmap=plt.cm.Pastel1,\n",
    "        alpha=0.8)\n",
    "\n",
    "plt.scatter(X0[:,0], X0[:, 1], color=\"red\")\n",
    "plt.scatter(X1[:,0], X1[:, 1], color=\"blue\")\n",
    "\n",
    "xlimit = [-8.2, 1.3]\n",
    "ylimit = [-8.2, 1.3]\n",
    "\n",
    "plt.xlim(xlimit); plt.ylim(ylimit)\n",
    "\n",
    "decision_function = SVMmodel.decision_function(data)\n",
    "support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\n",
    "support_vectors = data[support_vector_indices]\n",
    "\n",
    "plt.scatter(support_vectors[:,0], support_vectors[:,1],\n",
    "            s=100, facecolor=\"none\", edgecolors=\"k\")\n",
    "\n",
    "DecisionBoundaryDisplay.from_estimator(SVMmodel, data, ax=plt.gca(),    \n",
    "        grid_resolution=50, plot_method=\"contour\", levels=[-1, 0, 1],        \n",
    "        colors=\"k\", alpha=0.5, linestyles=[\"--\", \"-\", \"--\"])\n",
    "\n",
    "#%% define SVM plot (additional)\n",
    "def SVMplot(SVMmodel, data, group):\n",
    "    X0, X1 = data[group==1], data[group==2]\n",
    "    \n",
    "    DecisionBoundaryDisplay.from_estimator(SVMmodel, data, ax=plt.gca(),\n",
    "            grid_resolution=2000, response_method=\"predict\", cmap=plt.cm.Pastel1,\n",
    "            alpha=0.8)\n",
    "    \n",
    "    plt.scatter(X0[:,0], X0[:, 1], color=\"red\")\n",
    "    plt.scatter(X1[:,0], X1[:, 1], color=\"blue\")\n",
    "    \n",
    "    xlimit = [-8.2, 1.3]\n",
    "    ylimit = [-8.2, 1.3]\n",
    "    \n",
    "    plt.xlim(xlimit); plt.ylim(ylimit)\n",
    "    \n",
    "    decision_function = SVMmodel.decision_function(data)\n",
    "    support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\n",
    "    support_vectors = data[support_vector_indices]\n",
    "    \n",
    "    plt.scatter(support_vectors[:,0], support_vectors[:,1],\n",
    "                s=100, facecolor=\"none\", edgecolors=\"k\")\n",
    "    \n",
    "    DecisionBoundaryDisplay.from_estimator(SVMmodel, data, ax=plt.gca(),\n",
    "            grid_resolution=50, plot_method=\"contour\", levels=[-1, 0, 1],\n",
    "            colors=\"k\", alpha=0.5, linestyles=[\"--\", \"-\", \"--\"])\n",
    "\n",
    "SVMplot(SVMmodel, data, group)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
